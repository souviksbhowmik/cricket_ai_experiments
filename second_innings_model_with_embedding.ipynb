{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,accuracy_score\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pickle\n",
    "\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_date_parser = lambda x: datetime.strptime(x, \"%Y-%m-%d\")\n",
    "second_inn_feature_df = pd.read_csv('csv_data/feature_second_innings.csv',parse_dates=['match_date'],date_parser=custom_date_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_inn_feature_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_inn_result_df_train=pd.read_csv('csv_data/result_df_tran.csv',parse_dates=['match_date'],date_parser=custom_date_parser)\n",
    "# first_inn_result_df_test=pd.read_csv('csv_data/result_df_test.csv',parse_dates=['match_date'],date_parser=custom_date_parser)\n",
    "# lr_first_innings=pickle.load(open('first_innings_linear_regression.pkl','rb'))\n",
    "# scaler_first_innings = pickle.load(open('first_innings_linear_regression_scaler.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_innings_feature_columns = ['team_score', 'opponent_score', 'location_base', 'location_mean','batsman_mean', 'batsman_max', 'bowler_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_inn_feature_train = second_inn_feature_df[second_inn_feature_df['is_train']==True]\n",
    "# second_inn_feature_test = second_inn_feature_df[second_inn_feature_df['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'match_date', 'team', 'opponent', 'location', 'team_score',\n",
       "       'opponent_score', 'opponent_base', 'opponent_trend',\n",
       "       'opponent_trend_predict', 'opponent_mean', 'location_base',\n",
       "       'location_trend', 'location_trend_predict', 'location_mean',\n",
       "       'current_base', 'current_trend', 'current_trend_predict',\n",
       "       'current_mean', 'batsman_mean', 'batsman_max', 'bowler_mean',\n",
       "       'bowler_max', 'is_train', 'noise', 'target_score', 'runs_scored',\n",
       "       'win'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_inn_feature_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_innings_feature_columns = ['team_score',\n",
    "       'opponent_score', 'opponent_base', 'opponent_trend',\n",
    "       'opponent_trend_predict', 'opponent_mean', 'location_base',\n",
    "       'location_trend', 'location_trend_predict', 'location_mean',\n",
    "       'current_base', 'current_trend', 'current_trend_predict',\n",
    "       'current_mean', 'batsman_mean', 'batsman_max', 'bowler_mean',\n",
    "       'bowler_max','target_score']\n",
    "\n",
    "# second_innings_feature_columns = ['team_score',\n",
    "#         'batsman_mean', 'batsman_max', 'bowler_mean',\n",
    "#        'target_score']\n",
    "\n",
    "second_innings_target = ['win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    # load json and create model\n",
    "    json_file = open(model_name+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(model_name+\".h5\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all models and encoding maps\n",
    "\n",
    "country_enc_map=pickle.load(open('country_enc_map.pkl','rb'))\n",
    "loc_enc_map=pickle.load(open('loc_enc_map.pkl','rb'))\n",
    "group_encode_model_V2 = load_model('group_encode_model_V2')\n",
    "\n",
    "batsman_enc_map = pickle.load(open('batsman_enc_map.pkl','rb'))\n",
    "loc_enc_map_for_batsman = pickle.load(open('loc_enc_map_for_batsman.pkl','rb'))\n",
    "batsman_group_encode_model = load_model('batsman_group_encode_model')\n",
    "\n",
    "#v1\n",
    "#enc_map = pickle.load(open('country_location_enc_map.pkl','rb'))\n",
    "#group_encode_model_V1 = load_model('group_encode_model')\n",
    "\n",
    "match_stats_df = pd.read_csv('csv_data/match_stats.csv')\n",
    "match_summary_df = pd.read_csv('csv_data/match_list.csv',parse_dates=['date'],date_parser=custom_date_parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1377, 11), (1562, 48))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_summary_df.shape,match_stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_match_summary_df=match_summary_df.merge(match_stats_df,on='match_id',how='inner')\n",
    "recent_match_summary_df=recent_match_summary_df[recent_match_summary_df['second_innings']==recent_match_summary_df['team_statistics']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oh_pos(pos):\n",
    "    vec=np.zeros((11)).astype(int) \n",
    "    vec[pos-1]=1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_match_id_list = list(second_inn_feature_df['match_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recent_match_summary_df[['second_innings','team_statistics']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a254d8e197eb495eb4baa8d601a914e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=781.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feature_match_id_list = list(second_inn_feature_df['match_id'].unique())\n",
    "\n",
    "match_id_train_list = []\n",
    "match_id_test_list = []\n",
    "\n",
    "encoding_train_list = []\n",
    "encoding_test_list = []\n",
    "\n",
    "target_train_list = []\n",
    "target_test_list =[]\n",
    "no_of_rows = recent_match_summary_df.shape[0]\n",
    "#print(no_of_rows)\n",
    "for pos in tqdm(range(no_of_rows)):\n",
    "    match_details = recent_match_summary_df.iloc[pos]\n",
    "    match_id = match_details['match_id']\n",
    "    if match_id not in feature_match_id_list:\n",
    "        continue\n",
    "    location = match_details['location']\n",
    "    team = match_details['second_innings']\n",
    "    opposition = match_details['first_innings']\n",
    "    #total_run = match_details['total_run']\n",
    "    is_train = match_details['train_data']\n",
    "    \n",
    "    loc_oh = loc_enc_map_for_batsman[location]\n",
    "    opposition_oh = country_enc_map[opposition]\n",
    "    \n",
    "    batsman_oh_list =[]\n",
    "    position_oh_list =[]\n",
    "    loc_oh_list =[]\n",
    "    opposition_oh_list =[]\n",
    "    #print('getting batsman details')\n",
    "    for bi in range(11):\n",
    "        batsman = match_details['batsman_'+str(bi+1)]\n",
    "        if batsman == 'not_batted':\n",
    "            break\n",
    "            #batsman_oh = batsman_enc_map[batsman]\n",
    "        else:\n",
    "            batsman_oh = batsman_enc_map[team.strip()+' '+batsman.strip()]\n",
    "        position_oh = get_oh_pos(bi+1)\n",
    "        \n",
    "        batsman_oh_list.append(batsman_oh)\n",
    "        position_oh_list.append(position_oh)\n",
    "        loc_oh_list.append(loc_oh)\n",
    "        opposition_oh_list.append(opposition_oh)\n",
    "        \n",
    "    batsman_mat = np.stack(batsman_oh_list)\n",
    "    position_mat = np.stack(position_oh_list)\n",
    "    loc_mat = np.stack(loc_oh_list)\n",
    "    opposition_mat = np.stack(opposition_oh_list)\n",
    "    #print('encoding')\n",
    "    batsman_group_enc_mat = batsman_group_encode_model.predict([batsman_mat,position_mat,loc_mat,opposition_mat])\n",
    "    batsman_mean =  batsman_group_enc_mat.sum(axis=0) \n",
    "    #batsman_mean = batsman_group_enc_mat.reshape(-1)\n",
    "    \n",
    "    ##create team_encoding with V2\n",
    "    \n",
    "    team_oh_v = np.array(country_enc_map[team]).reshape(1,-1)\n",
    "    opponent_oh_v = np.array(opposition_oh).reshape(1,-1)\n",
    "    if location not in loc_enc_map:\n",
    "        continue\n",
    "    loc_oh_v=np.array(loc_enc_map[location]).reshape(1,-1)\n",
    "    country_enc_vec = group_encode_model_V2.predict([team_oh_v,opponent_oh_v,loc_oh_v]).reshape(-1)\n",
    "\n",
    "    ##create team_encoding with V1\n",
    "    \n",
    "#     team_oh_v = np.array(enc_map[team]).reshape(1,-1)\n",
    "#     opponent_oh_v = np.array(enc_map[opposition]).reshape(1,-1)\n",
    "#     if location not in loc_enc_map:\n",
    "#         continue\n",
    "#     loc_oh_v=np.array(enc_map[location]).reshape(1,-1)\n",
    "#     country_enc_vec = group_encode_model_V1.predict([team_oh_v,opponent_oh_v,loc_oh_v]).reshape(-1)\n",
    "    \n",
    "    #engineered_features\n",
    "    \n",
    "    feature_vector = np.array(second_inn_feature_df[second_inn_feature_df['match_id']==match_id][second_innings_feature_columns]).reshape(-1)\n",
    "    win = second_inn_feature_df[second_inn_feature_df['match_id']==match_id]['win'].values[0]\n",
    "\n",
    "    \n",
    "    final_vector = np.concatenate([batsman_mean,country_enc_vec,feature_vector])\n",
    "    \n",
    "    if is_train:\n",
    "        encoding_train_list.append(final_vector)\n",
    "        target_train_list.append(win)\n",
    "        match_id_train_list.append(match_id)\n",
    "    else:\n",
    "        encoding_test_list.append(final_vector)\n",
    "        target_test_list.append(win)\n",
    "        match_id_test_list.append(match_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_innings_scaler = StandardScaler()\n",
    "\n",
    "encoding_mat_train = np.stack(encoding_train_list)\n",
    "x_train = second_innings_scaler.fit_transform(encoding_mat_train)\n",
    "y_train = np.stack(target_train_list)\n",
    "\n",
    "encoding_mat_test = np.stack(encoding_test_list)\n",
    "x_test = second_innings_scaler.transform(encoding_mat_test)\n",
    "y_test = np.stack(target_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_lgr = lgr.predict(x_train)\n",
    "y_test_predict_lgr = lgr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_train_predict_lgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8581560283687943"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_predict_lgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict_lgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lgr,open('second_innings_model_with_embedding_lrg.pkl','wb'))\n",
    "pickle.dump(second_innings_scaler,open('second_innings_scaler_with_embedding.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining with first innings results\n",
    "(from simple linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_inn_feature_test_copy = pd.DataFrame(second_inn_feature_test)\n",
    "# second_inn_feature_train_copy = pd.DataFrame(second_inn_feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# second_inn_feature_test_copy = second_inn_feature.merge(first_inn_result_df_test[['match_id','first_innings_prediction']],\n",
    "#                                    on='match_id',\n",
    "#                                    how='inner')\n",
    "# second_inn_feature_train_copy = second_inn_feature.merge(first_inn_result_df_train[['match_id','first_innings_prediction']],\n",
    "#                                    on='match_id',\n",
    "#                                    how='inner')\n",
    "\n",
    "# second_inn_feature_test_copy['target_score'] = second_inn_feature_test_copy['first_innings_prediction']\n",
    "# second_inn_feature_train_copy['target_score'] = second_inn_feature_train_copy['first_innings_prediction']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_copy = second_innings_scaler.transform(second_inn_feature_train_copy[second_innings_feature_columns])\n",
    "# y_train_copy = second_inn_feature_train_copy[second_innings_target]\n",
    "\n",
    "# x_test_copy = second_innings_scaler.transform(second_inn_feature_test_copy[second_innings_feature_columns])\n",
    "# y_test_copy = second_inn_feature_test_copy[second_innings_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_copy_predict_lgr = lgr.predict(x_train_copy)\n",
    "# y_test_copy_predict_lgr = lgr.predict(x_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(y_train_copy,y_train_copy_predict_lgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(y_test_copy,y_test_copy_predict_lgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining with first innings results\n",
    "(obtained using best model-team embedding+batsman embedding+selected features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_innings_emb_prediction_train = pd.read_csv('csv_data/first_innings_embedding_prediction_train.csv')\n",
    "first_innings_emb_prediction_test = pd.read_csv('csv_data/first_innings_embedding_prediction_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_inn_feature_test_copy = pd.DataFrame(second_inn_feature_test)\n",
    "# second_inn_feature_train_copy = pd.DataFrame(second_inn_feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_inn_feature_test_copy = second_inn_feature_df.merge(first_innings_emb_prediction_test[['match_id','predicted_first_innings_runs']],\n",
    "                                   on='match_id',\n",
    "                                   how='inner')\n",
    "second_inn_feature_train_copy = second_inn_feature_df.merge(first_innings_emb_prediction_train[['match_id','predicted_first_innings_runs']],\n",
    "                                   on='match_id',\n",
    "                                   how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_inn_feature_test_copy['target_score'] = second_inn_feature_test_copy['predicted_first_innings_runs']\n",
    "second_inn_feature_train_copy['target_score'] = second_inn_feature_train_copy['predicted_first_innings_runs']\n",
    "\n",
    "second_inn_feature_df_copy = pd.concat([second_inn_feature_train_copy,second_inn_feature_test_copy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8985d689fa14312a7b5649741aa4049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=781.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feature_match_id_list = list(second_inn_feature_df_copy['match_id'].unique())\n",
    "\n",
    "match_id_train_list = []\n",
    "match_id_test_list = []\n",
    "\n",
    "encoding_train_list = []\n",
    "encoding_test_list = []\n",
    "\n",
    "target_train_list = []\n",
    "target_test_list =[]\n",
    "no_of_rows = recent_match_summary_df.shape[0]\n",
    "#print(no_of_rows)\n",
    "for pos in tqdm(range(no_of_rows)):\n",
    "    match_details = recent_match_summary_df.iloc[pos]\n",
    "    match_id = match_details['match_id']\n",
    "    if match_id not in feature_match_id_list:\n",
    "        continue\n",
    "    location = match_details['location']\n",
    "    team = match_details['second_innings']\n",
    "    opposition = match_details['first_innings']\n",
    "    #total_run = match_details['total_run']\n",
    "    is_train = match_details['train_data']\n",
    "    \n",
    "    loc_oh = loc_enc_map_for_batsman[location]\n",
    "    opposition_oh = country_enc_map[opposition]\n",
    "    \n",
    "    batsman_oh_list =[]\n",
    "    position_oh_list =[]\n",
    "    loc_oh_list =[]\n",
    "    opposition_oh_list =[]\n",
    "    #print('getting batsman details')\n",
    "    for bi in range(11):\n",
    "        batsman = match_details['batsman_'+str(bi+1)]\n",
    "        if batsman == 'not_batted':\n",
    "            break\n",
    "            #batsman_oh = batsman_enc_map[batsman]\n",
    "        else:\n",
    "            batsman_oh = batsman_enc_map[team.strip()+' '+batsman.strip()]\n",
    "        position_oh = get_oh_pos(bi+1)\n",
    "        \n",
    "        batsman_oh_list.append(batsman_oh)\n",
    "        position_oh_list.append(position_oh)\n",
    "        loc_oh_list.append(loc_oh)\n",
    "        opposition_oh_list.append(opposition_oh)\n",
    "        \n",
    "    batsman_mat = np.stack(batsman_oh_list)\n",
    "    position_mat = np.stack(position_oh_list)\n",
    "    loc_mat = np.stack(loc_oh_list)\n",
    "    opposition_mat = np.stack(opposition_oh_list)\n",
    "    #print('encoding')\n",
    "    batsman_group_enc_mat = batsman_group_encode_model.predict([batsman_mat,position_mat,loc_mat,opposition_mat])\n",
    "    batsman_mean =  batsman_group_enc_mat.sum(axis=0) \n",
    "    #batsman_mean = batsman_group_enc_mat.reshape(-1)\n",
    "    \n",
    "    ##create team_encoding with V2\n",
    "    \n",
    "    team_oh_v = np.array(country_enc_map[team]).reshape(1,-1)\n",
    "    opponent_oh_v = np.array(opposition_oh).reshape(1,-1)\n",
    "    if location not in loc_enc_map:\n",
    "        continue\n",
    "    loc_oh_v=np.array(loc_enc_map[location]).reshape(1,-1)\n",
    "    country_enc_vec = group_encode_model_V2.predict([team_oh_v,opponent_oh_v,loc_oh_v]).reshape(-1)\n",
    "\n",
    "    ##create team_encoding with V1\n",
    "    \n",
    "#     team_oh_v = np.array(enc_map[team]).reshape(1,-1)\n",
    "#     opponent_oh_v = np.array(enc_map[opposition]).reshape(1,-1)\n",
    "#     if location not in loc_enc_map:\n",
    "#         continue\n",
    "#     loc_oh_v=np.array(enc_map[location]).reshape(1,-1)\n",
    "#     country_enc_vec = group_encode_model_V1.predict([team_oh_v,opponent_oh_v,loc_oh_v]).reshape(-1)\n",
    "    \n",
    "    #engineered_features\n",
    "    \n",
    "    feature_vector = np.array(second_inn_feature_df_copy[second_inn_feature_df_copy['match_id']==match_id][second_innings_feature_columns]).reshape(-1)\n",
    "    win = second_inn_feature_df_copy[second_inn_feature_df_copy['match_id']==match_id]['win'].values[0]\n",
    "\n",
    "    \n",
    "    final_vector = np.concatenate([batsman_mean,country_enc_vec,feature_vector])\n",
    "    \n",
    "    if is_train:\n",
    "        encoding_train_list.append(final_vector)\n",
    "        target_train_list.append(win)\n",
    "        match_id_train_list.append(match_id)\n",
    "    else:\n",
    "        encoding_test_list.append(final_vector)\n",
    "        target_test_list.append(win)\n",
    "        match_id_test_list.append(match_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_mat_train = np.stack(encoding_train_list)\n",
    "x_train_copy = second_innings_scaler.transform(encoding_mat_train)\n",
    "y_train_copy = np.stack(target_train_list)\n",
    "\n",
    "encoding_mat_test = np.stack(encoding_test_list)\n",
    "x_test_copy = second_innings_scaler.transform(encoding_mat_test)\n",
    "y_test_copy = np.stack(target_test_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_copy_predict_lgr = lgr.predict(x_train_copy)\n",
    "y_test_copy_predict_lgr = lgr.predict(x_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9126637554585153, 0.8440366972477065)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train_copy,y_train_copy_predict_lgr),accuracy_score(y_test_copy,y_test_copy_predict_lgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#second_inn_feature_df_copy.merge(second_inn_feature_df,on='match_id',how='inner')[['target_score_x','target_score_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_copy_predict_lgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1144156"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_id_test_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.68048408, -0.6710452 , -1.73575387, -0.58598919, -0.67093961,\n",
       "       -0.66241659, -0.6597    , -0.9662108 , -1.33521158, -1.0786623 ,\n",
       "        0.4609055 ,  0.        ,  0.2566267 ,  0.43395915,  0.36384617,\n",
       "        0.34953377,  0.        ,  0.2890143 ,  0.        ,  0.34725311,\n",
       "       -1.5812828 , -1.21064089, -1.22623342,  0.        ,  0.        ,\n",
       "       -1.37832653, -1.11351011, -1.40918541, -1.39398236, -1.31134461,\n",
       "       -1.39280565, -1.48893338, -1.59222951, -1.52886508, -1.57832128,\n",
       "       -1.27367422,  0.        , -1.44798417, -1.57764853, -1.46306953,\n",
       "        0.73934402,  0.05712315, -0.40674332, -0.06709866, -0.54077266,\n",
       "       -0.93546584,  0.21386306, -0.14791468,  0.02021795,  0.20315482,\n",
       "        2.14530766, -1.87893186, -1.13044927,  0.90494331,  0.75026558,\n",
       "        1.15873729,  0.13938544, -0.54412314,  0.83929708])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_copy[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.7, gamma='auto', kernel='linear', probability=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=0.7,gamma='auto',kernel='linear',probability=True)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_svm = clf.predict(x_train)\n",
    "y_test_predict_svm = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9157894736842105, 0.8652482269503546)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_train_predict_svm),accuracy_score(y_test,y_test_predict_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_copy_predict_svm = lgr.predict(x_train_copy)\n",
    "y_test_copy_predict_svm = lgr.predict(x_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9126637554585153, 0.8440366972477065)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train_copy,y_train_copy_predict_svm),accuracy_score(y_test_copy,y_test_copy_predict_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf,open('second_innings_model_with_embedding_svm.pkl','wb'))\n",
    "#pickle.dump(second_innings_scaler,open('second_innings_scaler_with_embedding.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_nb = nb.predict(x_train)\n",
    "y_test_predict_nb = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8298245614035088, 0.7659574468085106)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_train_predict_nb),accuracy_score(y_test,y_test_predict_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensor230/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:12:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=40, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model = XGBClassifier(max_depth=3,n_estimators=40)\n",
    "xg_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_xg = xg_model.predict(x_train)\n",
    "y_test_predict_xg = xg_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8297872340425532)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_train_predict_xg),accuracy_score(y_test,y_test_predict_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor230",
   "language": "python",
   "name": "tensor230"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
